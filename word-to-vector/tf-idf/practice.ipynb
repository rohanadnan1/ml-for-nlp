{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "messages= pd.read_csv('data.csv', sep='\\t', names=['label','message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham Hello, how are you today?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham I'll call you later.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham Are we still meeting tomorrow?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham Don't forget to bring the documents.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham See you at the office at 10 AM.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham Can we reschedule the meeting to next Monday?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spam    You won a $1000 gift card! Click here ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spam    Urgent! Your account has been compromi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam    Congratulations, you have been selecte...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam    This is your final notice! Pay now to ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>spam    Earn $5000 from home in just 5 hours a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam    Get a free vacation with our exclusive...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam    Limited-time offer: Buy one, get one f...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>spam    You have an unclaimed reward waiting. ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>spam    Win big! Enter the lottery for a chanc...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spam    Act now and receive a discount on your...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                label  message\n",
       "0                       ham Hello, how are you today?      NaN\n",
       "1                            ham I'll call you later.      NaN\n",
       "2                  ham Are we still meeting tomorrow?      NaN\n",
       "3            ham Don't forget to bring the documents.      NaN\n",
       "4                 ham See you at the office at 10 AM.      NaN\n",
       "5   ham Can we reschedule the meeting to next Monday?      NaN\n",
       "6   spam    You won a $1000 gift card! Click here ...      NaN\n",
       "7   spam    Urgent! Your account has been compromi...      NaN\n",
       "8   spam    Congratulations, you have been selecte...      NaN\n",
       "9   spam    This is your final notice! Pay now to ...      NaN\n",
       "10  spam    Earn $5000 from home in just 5 hours a...      NaN\n",
       "11  spam    Get a free vacation with our exclusive...      NaN\n",
       "12  spam    Limited-time offer: Buy one, get one f...      NaN\n",
       "13  spam    You have an unclaimed reward waiting. ...      NaN\n",
       "14  spam    Win big! Enter the lottery for a chanc...      NaN\n",
       "15  spam    Act now and receive a discount on your...      NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "corpus=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(messages)):\n",
    "    review=re.sub('[^a-zA-z]',' ',messages['label'][i])\n",
    "    review=review.lower()\n",
    "    review=review.split()\n",
    "    review=[lemmatizer.lemmatize(word) for word in review if word not in stopwords.words('english')]\n",
    "    review=' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ham', 'hello', 'today'],\n",
       " ['ham', 'call', 'later'],\n",
       " ['ham', 'still', 'meeting', 'tomorrow'],\n",
       " ['ham', 'forget', 'bring', 'document'],\n",
       " ['ham', 'see', 'office'],\n",
       " ['ham', 'please', 'confirm', 'appointment', 'next', 'week'],\n",
       " ['ham', 'sent', 'report', 'let', 'know', 'question'],\n",
       " ['ham', 'thank', 'purchase', 'order', 'arrive', 'soon'],\n",
       " ['ham', 'reschedule', 'meeting', 'next', 'monday'],\n",
       " ['ham', 'happy', 'birthday', 'hope', 'great', 'day'],\n",
       " ['spam', 'gift', 'card', 'click', 'claim'],\n",
       " ['spam', 'urgent', 'account', 'compromised', 'click', 'secure'],\n",
       " ['spam', 'congratulation', 'selected', 'prize', 'reply', 'claim'],\n",
       " ['spam', 'final', 'notice', 'pay', 'avoid', 'penalty'],\n",
       " ['spam', 'earn', 'home', 'hour', 'week', 'sign'],\n",
       " ['spam', 'get', 'free', 'vacation', 'exclusive', 'offer', 'call'],\n",
       " ['spam',\n",
       "  'limited',\n",
       "  'time',\n",
       "  'offer',\n",
       "  'buy',\n",
       "  'one',\n",
       "  'get',\n",
       "  'one',\n",
       "  'free',\n",
       "  'click',\n",
       "  'purchase'],\n",
       " ['spam', 'unclaimed', 'reward', 'waiting', 'click', 'redeem'],\n",
       " ['spam', 'win', 'big', 'enter', 'lottery', 'chance', 'win', 'million'],\n",
       " ['spam', 'act', 'receive', 'discount', 'next', 'purchase'],\n",
       " 'ham hello today',\n",
       " 'ham call later',\n",
       " 'ham still meeting tomorrow',\n",
       " 'ham forget bring document',\n",
       " 'ham see office',\n",
       " 'ham reschedule meeting next monday',\n",
       " 'spam gift card click claim',\n",
       " 'spam urgent account compromised click secure',\n",
       " 'spam congratulation selected prize reply claim',\n",
       " 'spam final notice pay avoid penalty',\n",
       " 'spam earn home hour week sign',\n",
       " 'spam get free vacation exclusive offer call',\n",
       " 'spam limited time offer buy one get one free click purchase',\n",
       " 'spam unclaimed reward waiting click redeem',\n",
       " 'spam win big enter lottery chance win million',\n",
       " 'spam act receive discount next purchase']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tdidf = TfidfVectorizer(max_features=100, ngram_range=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ham hello': np.int64(34), 'hello today': np.int64(42), 'ham call': np.int64(31), 'call later': np.int64(9), 'ham still': np.int64(39), 'still meeting': np.int64(83), 'meeting tomorrow': np.int64(51), 'ham forget': np.int64(32), 'forget bring': np.int64(24), 'bring document': np.int64(7), 'ham see': np.int64(37), 'see office': np.int64(70), 'ham please': np.int64(35), 'please confirm': np.int64(62), 'confirm appointment': np.int64(17), 'appointment next': np.int64(2), 'next week': np.int64(54), 'ham sent': np.int64(38), 'sent report': np.int64(72), 'report let': np.int64(67), 'let know': np.int64(47), 'know question': np.int64(46), 'ham thank': np.int64(40), 'thank purchase': np.int64(84), 'purchase order': np.int64(64), 'order arrive': np.int64(60), 'arrive soon': np.int64(3), 'ham reschedule': np.int64(36), 'reschedule meeting': np.int64(68), 'meeting next': np.int64(50), 'next monday': np.int64(52), 'ham happy': np.int64(33), 'happy birthday': np.int64(41), 'birthday hope': np.int64(6), 'hope great': np.int64(44), 'great day': np.int64(30), 'spam gift': np.int64(78), 'gift card': np.int64(29), 'card click': np.int64(10), 'click claim': np.int64(12), 'spam urgent': np.int64(81), 'urgent account': np.int64(87), 'account compromised': np.int64(0), 'compromised click': np.int64(16), 'click secure': np.int64(15), 'spam congratulation': np.int64(74), 'congratulation selected': np.int64(18), 'selected prize': np.int64(71), 'prize reply': np.int64(63), 'reply claim': np.int64(66), 'spam final': np.int64(76), 'final notice': np.int64(23), 'notice pay': np.int64(55), 'pay avoid': np.int64(61), 'avoid penalty': np.int64(4), 'spam earn': np.int64(75), 'earn home': np.int64(20), 'home hour': np.int64(43), 'hour week': np.int64(45), 'week sign': np.int64(90), 'spam get': np.int64(77), 'get free': np.int64(27), 'free vacation': np.int64(26), 'vacation exclusive': np.int64(88), 'exclusive offer': np.int64(22), 'offer call': np.int64(57), 'spam limited': np.int64(79), 'limited time': np.int64(48), 'time offer': np.int64(85), 'offer buy': np.int64(56), 'buy one': np.int64(8), 'one get': np.int64(59), 'get one': np.int64(28), 'one free': np.int64(58), 'free click': np.int64(25), 'click purchase': np.int64(13), 'spam unclaimed': np.int64(80), 'unclaimed reward': np.int64(86), 'reward waiting': np.int64(69), 'waiting click': np.int64(89), 'click redeem': np.int64(14), 'spam win': np.int64(82), 'win big': np.int64(91), 'big enter': np.int64(5), 'enter lottery': np.int64(21), 'lottery chance': np.int64(49), 'chance win': np.int64(11), 'win million': np.int64(92), 'spam act': np.int64(73), 'act receive': np.int64(1), 'receive discount': np.int64(65), 'discount next': np.int64(19), 'next purchase': np.int64(53)}\n"
     ]
    }
   ],
   "source": [
    "tdidf.fit(corpus)\n",
    "vocab = tdidf.vocabulary_\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming corpus is a list of lists of tokens\n",
    "corpus = [' '.join(tokens) for tokens in corpus]\n",
    "\n",
    "# Fit and transform the corpus using TfidfVectorizer\n",
    "X = tdidf.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
